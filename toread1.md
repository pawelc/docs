Learning to Predict by the Methods of Temporal Differences
Evolving Neural Turing Machines for Reward-based Learning
Scaling Memory-Augmented Neural Networks with Sparse Reads and Writes
Can Active Memory Replace Attention
End-To-End Memory Networks
Grid Long Short-Term Memory
Pointer networks
Neural Machine Translation by Jointly Learning to Align and Translate
Hard attention: 
Inferring Algorithmic Patterns with Stack-Augmented Recurrent Nets   
Show, Attend and Tell: Neural Image Caption Generation with Visual Attention
LIE-ACCESS NEURAL TURING MACHINES
Neural Programmer
Neural GPUs
Learning to Remember Rare Events
GENERATIVE TEMPORAL MODELS WITH MEMORY
Learning to Transduce with Unbounded Memory
Evolutionary multi-objective generation of recurrent neural network ensembles for time series prediction
Self-Delimiting Neural Networks
Optimal ordered problem solver
Applications of quantum inspired computational intelligence: a survey
Deep Learning for Time-Series Analysis
Modeling temporal dependencies in high-dimensional sequences: Application to polyphonic music generation and transcription
One-shot Learning with Memory-Augmented Neural Networks
Cortical microcircuits as gated-recurrent neural networks
Learning to Diagnose with LSTM Recurrent Neural Networks
Recurrent generative adversarial networks for proximal learning and automated compressive image recovery
Generalization of deep neural networks for chest pathology classification in x-rays using generative adversarial networks
Speech recognition with missing data using recurrent neural nets
Modeling Missing Data in Clinical Time Series with RNNs
Doctor AI: Predicting Clinical Events via Recurrent Neural Networks
DeepCare A Deep Dynamic Memory Model for Predictive Medicine
Directly Modeling Missing Data in Sequences with RNNs Improved Classification of Clinical Time Series
Differential recurrent neural networks for action recognition
https://machinelearningmastery.com/promise-recurrent-neural-networks-time-series-forecasting/
Supervised learning from incomplete data via an EM approach
Visualizing and Understanding Recurrent Networks (also video https://skillsmatter.com/skillscasts/6611-visualizing-and-understanding-recurrent-networks)
Framewise phoneme classiﬁcation with bidirectional LSTM and other neural network architectures
Training Recurrent Networks by Evolino
Evolving memory cell structures for sequence learning
Long Short-Term Memory Recurrent Neural Network Architectures for Large Scale Acoustic Modeling
An Empirical Exploration of Recurrent Network Architectures 
Long Short-Term Memory in Recurrent Neural Networks
LSTM can Solve Hard Long Time Lag Problems
Gradient Flow in Recurrent Nets the Difficulty of Learning Long-Term Dependencies
Stock Price Prediction via Discovering Multi-Frequency Trading Patterns
Accelerating Recurrent Neural Networks A Memory-Efficient Approach
Learning compact recurrent neural networks
Unsupervised Learning in Recurrent Neural Networks
Real-time interactive sequence generation and control with Recurrent Neural Network ensembles
From Bayesian Sparsity to Gated Recurrent Nets
Recurrent Additive Networks
Mixture density networks for distribution and uncertainty estimation
Long-term Recurrent Convolutional Networks for Visual Recognition and Description
Translating videos to natural language using deep recurrent neural networks
Video description generation incorporating spatiotemporal features and a soft-attention mechanism
Sequence to Sequence -- Video to Text
Recurrent Models of Visual Attention
Multiple Object Recognition with Visual Attention
DRAW: A Recurrent Neural Network For Image Generation
https://deepmind.com/blog/differentiable-neural-computers/
https://www.youtube.com/watch?v=steioHoiEms
https://github.com/deepmind/dnc
https://www.youtube.com/watch?v=QuvRWevJMZ4 - attention
https://distill.pub/2016/augmented-rnns/
Generative Adversarial Networks
Domain-Adversarial Neural Networks
Domain-Adversarial Training of Neural Networks
Learning Phrase Representations using RNN Encoder–Decoder for Statistical Machine Translation (this is about GRU)
Empirical evaluation of gated recurrent neural networks on sequence modeling
Depth-Gated LSTM
A clockwork RNN
A Recurrent Latent Variable Model for Sequential Data
Learning Stochastic Recurrent Networks
A Long Short-Term Memory Recurrent Neural Network Framework for Network Traffic Matrix Prediction
Structural-RNN: Deep Learning on Spatio-Temporal Graphs
Adaptive Computation Time for Recurrent Neural Networks
Spatially Adaptive Computation Time for Residual Networks (https://www.youtube.com/watch?v=xp5lLiA-hA8)
Training recurrent networks online without backtracking
A tutorial on training recurrent neural networks, covering BPPT, RTRL, EKF and the "echo state network" approach
Decoupled Neural Interfaces using Synthetic Gradients
Curriculum Learning
Active Learning Literature Survey
Unifying Count-Based Exploration and Intrinsic Motivation
Automated Curriculum Learning for Neural Networks
VIME Variational Information Maximizing Exploration
https://github.com/salesforce/pytorch-qrnn
Gradient-Based Learning Algorithms for Recurrent Networks and Their Computational Complexity
http://people.idsia.ch/~juergen/rnn.html
Learning to Control Fast-Weight Memories An Alternative to Dynamic Recurrent Networks
Extraction of rules from discrete-time recurrent neural networks
Deep learning in neural networks An overview
Learning Context Free Grammars Limitations of a Recurrent Neural Network with an External Stack Memory
A Connectionist Symbol Manipulator That Discovers the Structure of Context-Free Languages
Learning to control fast-weight memories: An alternative to recurrent nets
Learning Precise Timing with LSTM Recurrent Networks
An introspective network that can learn to run its own weight change algorithm
Learning To Learn Using Gradient Descent
Learning to learn by gradient descent by gradient descent
http://people.idsia.ch/~juergen/metalearner.html
Sequential Constant Size Compressors for Reinforcement Learning
Sequence Labelling in Structured Domains with Hierarchical Recurrent Neural Networks
Learning Complex, Extended Sequences Using the Principle of History Compression
Evolving Neural Networks in Compressed Weight Space
https://github.com/openai/multiagent-competition
https://blog.openai.com/competitive-self-play/
http://people.idsia.ch/~juergen/optimalsearch.html
http://people.idsia.ch/~juergen/evolino.html
Driven by Compression Progress A Simple Principle Explains Essential Aspects of Subjective Beauty, Novelty, Surprise, Interestingness, Attention, Curiosity, Creativity, Art, Science, Music, Jokes
Resource-Bounded Machines are Motivated to be Effective, Efficient, and Curious
https://aeon.co/essays/how-close-are-we-to-creating-artificial-intelligence
https://www.icsi.berkeley.edu/icsi/events/2014/08/schmidhuber-rnn
https://blog.openai.com/competitive-self-play/
https://github.com/openai/multiagent-competition
https://r2rt.com/styles-of-truncated-backpropagation.html
Statistical Language Models based on Neural Networks
On the difficulty of training recurrent neural networks
On Multiplicative Integration with Recurrent Neural Networks
Layer Normalization
https://r2rt.com/recurrent-neural-networks-in-tensorflow-ii.html
Deep Residual Learning for Image Recognition
Highway Networks
Learning Long-Term Dependencies with Gradient Descent is Difficult.
Protein Secondary Structure Prediction with Long Short Term Memory Networks
Random search for hyper-parameter optimization
An Efficient Approach for Assessing Hyperparameter Importance
Generalized Functional ANOVA Diagnostics for High-Dimensional Functions of Dependent Variables
Recurrent Highway Networks (https://github.com/julian121266/RecurrentHighwayNetworks)
Highway and Residual Networks learn Unrolled Iterative Estimation
DropIn: Making Reservoir Computing Neural Networks Robust to Missing Inputs by Dropout
Multi-directional Recurrent Neural Networks A Novel Method for Estimating Missing Data
Explaining Recurrent Neural Network Predictions in Sentiment Analysis
E-RNN Entangled Recurrent Neural Networks for Causal Prediction
Recurrent neural network based language model
Context dependent recurrent neural network language model
Deep Computational Phenotyping
An overview and comparative analysis of Recurrent Neural Networks for Short Term Load Forecasting
Predicting Remaining Useful Life using Time Series Embeddings based on Recurrent Neural Networks
m-TSNE: A Framework for Visualizing High-Dimensional Multivariate Time Series
Variational Recurrent Adversarial Deep Domain Adaptation
Grounded Recurrent Neural Networks
Second-order training for recurrent neural networks without teacher-forcing
Modeling Progression Free Survival in Breast Cancer with Tensorized Recurrent Neural Networks and Accelerated Failure Time Models
End-to-end attention-based large vocabulary speech recognition
Attention-Based Models for Speech Recognition
Sequence to Sequence Learning with Neural Networks
Generating sequences with recurrent neural networks
A note on the evaluation of generative models
Mind’s Eye: A Recurrent Visual Representation for Image Caption Generation
Time Series for Macroeconomics and Finance
Scheduled Sampling for Sequence Prediction with Recurrent Neural Networks
An Actor-Critic Algorithm for Sequence Prediction
Search-based structured prediction
A Reduction of Imitation Learning and Structured Prediction to No-Regret Online Learning
How (not) to Train your Generative Model: Scheduled Sampling, Likelihood, Adversary?
The neural autoregressive distribution estimator
Zoneout Regularizing RNNs by Randomly Preserving Hidden Activations
Recurrent neural networks with limited numerical precision
Batch normalized recurrent neural networks
Attention is all you need
Banishing the homunculus: making working memory work
Continuous attractors and oculomotor control
Expressive power of recurrent neural networks
https://arxiv.org/find/cs/1/au:+Fulcher_B/0/1/0/all/0/1
Variational Memory Addressing in Generative Models
https://github.com/openai/blocksparse
Distilling a Neural Network Into a Soft Decision Tree
Overcoming catastrophic forgetting in neural networks
Memory-based neural networks for robot learning
Learning Longer Memory in Recurrent Neural Networks
Neural GPUs Learn Algorithms
Ask Me Anything: Dynamic Memory Networks for Natural Language Processing
Prediction with a Short Memory
Can recurrent neural networks warp time?
Building machines that learn and think like people
Matching Networks for One Shot Learning
Learning Simple Algorithms from Examples
Associative Long Short-Term Memory
Meta-Learning with Memory-Augmented Neural Networks
Feedforward Sequential Memory Networks: A New Structure to Learn Long-term Dependency
Hierarchical Memory Networks
Memory-augmented Neural Machine Translation
LSTM with working memory
Active One-shot Learning
Position-based Content Attention for Time Series Forecasting with Sequence-to-sequence RNNs
Self-paced learning for latent variable models
Delving into adversarial attacks on deep policies
Kalman filters improve lstm network performance in problems unsolvable by traditional recurrent nets
Sequential Neural Models with Stochastic Layers
Memory-Efficient Backpropagation Through Time
The Future of Memory Remembering, Imagining, and the Brain
Is the brain a good model for machine intelligence
Evidence integration in model-based tree search
Artificial intelligence Deep neural reasoning
Kalman filtering and neural networks
Training recurrent networks using the extended kalman filter
An evolutionary algorithm that constructs recurrent neural networks
Evolutionary optimization of long short-term memory neural network language model
Long Short-Term Memory Over Tree Structures
Differential recurrent neural networks for action recognition
Semantic object parsing with local-global long short-term memory
Lstm time and frequency recurrence for automatic speech recognition
Convolutional lstm network: A machine learning approach for precipitation nowcasting
Towards ai-complete question answering a set of prerequisite toy tasks
Ask me anything: Dynamic memory networks for natural language processing
Recurrent memory network for language modeling
Learning longer memory in recurrent neural networks
Unitary evolution recurrent neural networks
Gated Orthogonal Recurrent Units: On Learning to Forget
Improving neural networks with dropout
Rnndrop: A novel dropout for rnns in asr
Recurrent dropout without memory loss
Regularizing rnns by stabilizing activations
PRNN Recurrent Neural Network with Persistent Memory
Cascade Dynamics Modeling with Attention-based Recurrent Neural Network
Attention-based Mixture Density Recurrent Networks for History-based Recommendation