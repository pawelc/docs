People:
http://www.cs.toronto.edu/~graves/
http://www.cs.toronto.edu/~ilya/
http://www0.cs.ucl.ac.uk/staff/d.silver/web/Home.html
https://people.eecs.berkeley.edu/~pabbeel/
http://www-etud.iro.umontreal.ca/~boulanni/
http://people.idsia.ch/~juergen/
Software:
https://github.com/fchollet/keras
https://github.com/karpathy/neuraltalk
Video:
http://cs231n.stanford.edu/
https://www.youtube.com/watch?v=xKt21ucdBY0
https://www.youtube.com/playlist?list=PLZHQObOWTQDPD3MizzM2xVFitgF8hE_ab
http://cs224d.stanford.edu/syllabus.html
Some other papers maybe worth reading
Learning to count without a counter A case study of dynamics and activation landscapes in recurrent networks
Recurrent Neural Networks Can Learn to Implement Symbol-Sensitive Counting
Connectionist Temporal Classification: Labelling Unsegmented Sequence Data with Recurrent Neural Networks
Multi-Dimensional Recurrent Neural Networks
Parallel Multi-Dimensional LSTM, With Application to Fast Biomedical Volumetric Image Segmentation
The Principled Design of Large-scale Recursive Neural Network Architectures–DAG-RNNs and the Protein Structure Prediction Problem
How to construct deep recurrent neural networks
TRAINING A NEURAL NETWORK WITH A FINANCIAL CRITERION RATHER THAN A PREDICTION CRITERION
Global optimization of a neural network-hidden Markov model hybrid
Recurrent Backpropagation and the Dynamical Approach to Adaptive Neural Computation
BPS: a learning algorithm for capturing the dynamical nature of speech
Robust speech recognition based on joint model and feature space optimization of hidden Markov models
Learning internal representations by error propagation
Connectionist Viterbi training: a new hybrid method for continuous speech recognition
Word recognition using hidden control neural architecture
Links between Markov models and multilayer perceptrons
Connectionist Speech Recognition. A Hybrid Approach (book)
A comparison of hybrid HMM architecture using global discriminating training
Alpha-nets A recurrent ‘neural’ network architecture with a hidden Markov model interpretation
Continuous speech recognition using multilayer perceptrons with hidden Markov models
Continuous speech recognition by connectionist statistical methods
Context-dependent connectionist probability estimation in a hybrid hidden Markov model-neural net speech recognition system
Speech recognition using deep neural network - recent trends
An application of recurrent nets to phone probability estimation
A speech recognition method based on the sequential multi-layer perceptrons
New discriminative training algorithms based on the generalized probabilistic descent method
Speech recognition using neural networks with forward-backward probability generated targets
Non-linear input transformations for discriminative HMMs
Hidden neural networks: a framework for HMM/NN hybrids
Maximum mutual information neural networks for hybrid connectionist-HMM speech recognition systems
Something about TDNN
Nonlinear dynamic boltzmann machines for time-series prediction
Finding structure in time
Deep, Convolutional, and Recurrent Models for Human Activity Recognition using Wearables
Learning from hints in neural networks
Including Hints in Training Neural Nets
Sparse Kalman Filtering Approaches to Covariance Estimation from High Frequency Data in the Presence of Jumps
Generalization and network design strategies
Modularity and scaling in large phonemic neural networks
Articial Neural Networks and their Application to Sequence Recognition
Tangent prop - A formalism for specifying selected invariances in an adaptive network
Re-Sign: Re-Aligned End-to-End Sequence Modelling with Deep Recurrent CNN-HMMs
Unified integration of explicit knowledge and learning by example in recurrent networks
Programmable execution of multi-layered networks for automatic speech recognition
Adaptive mixtures of local experts
Phoneme Recognition Using Time Delay Neural Networks
Boosted Backpropagation Learning for Training Deep Modular Networks
Training Stochastic Model Recognition Algorithms as Networks can Lead to Maximum Mutual Information Estimation of Parameters
Combining hidden Markov model and neural network classifiers
A hybrid continuous speech recognition system using segmental neural nets with hidden Markov models
Artificial Neural Networks and their Application to Sequence Recognition
Time-Warping Network: A Hybrid Framework for Speech Recognition
An introduction to the application of the theory of probabilistic functions of a Markov process to automatic speech recognition
Identifying and attacking the saddle point problem in high-dimensional non-convex
optimization
All you need is a good init
Weight Normalization: A Simple Reparameterization to Accelerate Training of Deep Neural Networks 
Big Neural Networks Waste Capacity
An empirical evaluation of recurrent network architectures
Delving Deep into Rectifiers: Surpassing Human-Level Performance on ImageNet Classification
Natural Neural Networks
Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift
On the diﬃculty of training Recurrent Neural Networks
Adam: A method for stochastic optimization
From Machine Learning to Machine Reasoning 
Natural Language Processing (almost) from Scratch
A Tutorial on Energy-Based Learning 
Improving Stochastic Gradient Descent with Feedback
Primal-dual subgradient methods for convex problems (how to make models sparse)
Ad Click Prediction: a View from the Trenches (how to make models sparse), look at FTRLOptimizer in TensorFlow
Dropout: A Simple Way to Prevent Neural Networks from Overﬁtting
A theoretically grounded application of dropout in recurrent neural networks
Revisiting Distributed Synchronous SGD
https://petewarden.com/2016/05/03/how-to-quantize-neural-networks-with-tensorflow/
https://en.wikipedia.org/wiki/Xgboost
Is object localization for free? – Weakly-supervised learning with convolutional neural networks
End-to-end people detection in crowded scenes
Fully Convolutional Networks for Semantic Segmentation
Very Deep Convolutional Networks for Large-Scale Visual Recognition
Inception-v4, Inception-ResNet and the Impact of Residual Connections on Learning
Unit Tests for Stochastic Optimization
https://github.com/tensorflow/tensorflow/blob/r0.10/tensorflow/examples/tutorials/deepdream/deepdream.ipynb
https://magenta.tensorflow.org/
A Comparative Study of the Performance of HMM, DNN, and RNN based Speech Synthesis Systems Trained on Very Large Speaker-Dependent Corpora
Rethinking the Inception Architecture for Computer Vision
How transferable are features in deep neural networks
Deeply-Supervised Nets
Global continuation for distance geometry problems
A Theoretical Analysis of Optimization by Gaussian Continuation
Neural network learning control of robot manipulators using gradually increasing task difficulty
Learning to execute
Recurrent Neural Network Regularization
LSTM A Search Space Odyssey
https://www.tensorflow.org/tutorials/seq2seq
https://www.tensorflow.org/tutorials/word2vec
http://colah.github.io/posts/2014-07-NLP-RNNs-Representations/
http://ruder.io/word-embeddings-1/
On Using Very Large Target Vocabulary for Neural Machine Translation
Long Short-Term Memory-Networks for Machine Reading
Show, Attend and Tell: Neural Image Caption Generation with Visual Attention
PatternNet and PatternLRP Improving the interpretability of neural networks
EXPLAINING AND HARNESSING ADVERSARIAL EXAMPLES
Deep Neural Networks are Easily Fooled: High Confidence Predictions for Unrecognizable Images
https://medium.com/merantix/picasso-a-free-open-source-visualizer-for-cnns-d8ed3a35cfc5
https://github.com/merantix/picasso
Maxout networks
A Theoretical Analysis of Feature Pooling in Visual Recognition
Ask the locals: multi-way local pooling for image recognition
Beyond spatial pyramids: Receptive ﬁeld learning for pooled image features
Convolutional Sequence to Sequence Learning
Convolutional Recurrent Neural Networks: Learning Spatial Dependencies for Image Representation
Emergence of Complex-Like Cells in a Temporal Product Network with Local Receptive Fields
Multidimensional, Downsampled Convolution for Autoencoders
Perception in chess
Auto Encoding variational bayes with example from the book and “Tutorial on Variational Autoencoders”
Contractive Auto-Encoders: Explicit Invariance During Feature Extraction
Stacked Convolutional Auto-Encoders for Hierarchical Feature Extraction
GSNs: Generative Stochastic Networks
Winner-Take-All Autoencoders
Adversarial Autoencoders
Semantic Hashing
CNN Based Hashing for Image Retrieval
Recurrent Convolutional Neural Networks for Scene Parsing
From image-level to pixel-level labeling with convolutional networks
Joint training of a convolutional network and a graphical model for human pose estimation
Deep learning of invariant spatio-temporal features from video
Mechanisms underlying visual object recognition
Learning where to attend with deep architectures for image tracking
The development of the time-delay neural network architecture for speech recognition
Phoneme recognition using time-delay neural networks
A Time-Delay Neural Network Architecture for Isolated Word Recognition
Learning representations by back-propagating errors.
Turing computability with neural nets
Computation Beyond the Turing Limit
On the Computational Power of Neural Nets
Turing machines are recurrent neural networks
https://www.oreilly.com/ideas/reinforcement-learning-for-complex-goals-using-tensorflow
https://www.youtube.com/watch?v=PwOnsT2UW5o
Multi-digit number recognition from Street View imagery using deep convolutional neural networks
Bidirectional recurrent neural networks
On Supervised Learning from Sequential Data With Applications for Speech Recognition
Sequence Learning lectures (book) -  Bidirectional Dynamics for Protein Secondary Structure Prediction
Capturing Long-term Dependencies for Protein Secondary Structure Prediction
Bidirectional Long Short-Term Memory Networks for Predicting the Subcellular Localization of Eukaryotic Proteins
Experiments on Learning by Back Propagation
Offline handwriting recognition with multidimensional recurrent neural networks
Unconstrained on-line handwriting recognition with recurrent neural networks
Speech recognition with deep recurrent neural networks Graves
Exploiting the past and the future in protein secondary structure prediction
ReNet: A recurrent neural network based alternative to convolutional networks
Markovian Models for Sequential Data
Probable Networks and Plausible Predictions - a Review of Practical Bayesian Methods for Supervised Neural Networks
Bayesian Learning for Neural Networks
The Echo State Approach to Analysing and Training Recurrent Neural Networks
On the approximation capability of recurrent neural networks
Forecasting with Recurrent Neural Networks 12 Tricks
Gradient Flow in Recurrent Nets: the Difficulty of Learning Long-Term Dependencies
Fast Model-based Protein Homology Detection without Alignment.
Gradient-Based Learning Algorithms for Recurrent Networks and Their Computational Complexity
Fast Curvature Matrix-Vector Products for Second-Order Gradient Descent
An Analysis of Noise in Recurrent Neural Networks: Convergence and Generalization
A comparison of preprocessors for the cambridge recurrent error propagation network speech recognition system
Learning Long-Term Dependencies in NARX Recurrent Neural Networks
Learning long-term dependencies is not as diﬃcult with NARX recurrent neural networks
Induction of Multiscale Temporal Structure
LSTM recurrent networks learn simple context-free and context-sensitive languages
Finding temporal structure in music: blues improvisation with LSTM recurrent networks
Reinforcement Learning with Long Short-Term Memory
A Novel Approach to On-Line Handwriting Recognition Based on Bidirectional Long Short-Term Memory Networks
Modeling systems with internal state using evolino
Experiments on the Implementation of Recurrent Neural Networks for Speech Phone Recognition 
Rapid Retraining on Speech Data with LSTM Recurrent Networks
Introduction to the Special Issue on Meta-Learning
Hierarchical Recurrent Neural Networks for Long-Term Dependencies
Discovering multiscale dynamical features with hierarchical Echo State Networks
Recursive distributed representations
From machine learning to machine reasoning
On the eﬃcient classiﬁcation of data structures by neural networks
A general framework for adaptive processing of data structures
Dynamic pooling and unfolding recursive autoencoders for paraphrase detection
Semi-supervised recursive autoencoders for predicting sentiment distributions
Recursive deep models for semantic compositionality over a sentiment treebank
Parsing Natural Scenes and Natural Language with Recursive Neural Networks
Large scale image annotation: learning to rank with joint word-image embeddings
Bifurcations of Recurrent Neural Networks in Gradient Descent Learning
Random walks: Training very deep nonlinear feed-forward networks with smart initialization
The problem of learning long-term dependencies in recurrent networks
Adaptive nonlinear system identiﬁcation with echo state networks
Real-time computing without stable states: A new framework for neural computation based on perturbations
Harnessing nonlinearity: Predicting chaotic systems and saving energy in wireless communication
Echo state network (http://www.scholarpedia.org/article/Echo_state_network)
Reservoir computing approaches to recurrent neural network training
Re-visiting the echo state property
Long Short-Term Memory in Echo State Networks: Details of a Simulation Study
Training Recurrent Neural Networks
On the importance of initialization and momentum in deep learning
Artiﬁcial Neural Networks and their Application to Sequence Recognition
Optimization and applications of echo state networks with leakyintegrator neurons
Bidirectional LSTM Networks for Improved Phoneme Classification and Recognition
Connectionist probability estimators in HMM speech recognition
LeRec: a NN/HMM hybrid for on-line handwriting recognition
Global Optimization of a Neural Network{Hidden Markov Model Hybrid
A new training algorithm for hybrid HMM/ANN speech recognition systems
Estimation of global posteriors and forward-backward training of hybrid HMM/ANN systems
Robust combination of neural networks and hidden Markov models for speech recognition
Reading checks with multilayer graph transformer networks
Gradient-Based Learning Applied to Document Recognition
Graph Transformer Networks for Image Recognition
Speaker-Adaptation for Hybrid HMM-ANN Continuous Speech Recognition System
Forward-Backward Retraining of Recurrent Neural Networks
A Neural Network Based, Speaker Independent, Large Vocabulary, Continuous Speech Recognition System: the Wernicke Project
Large Margin Hidden Markov Models for Automatic Speech Recognition
Conditional Random Fields: Probabilistic Models for Segmenting and Labeling Sequence Data
Capacity and complexity of HMM duration modeling techniques
Neural network design for J function approximation in dynamic programming
Modular DAG–RNN Architectures for Assembling Coarse Protein Structures
Supervised neural networks for the classification of structures
Recurrent networks for structured data – A unifying approach and its properties
A Scalable Machine Learning Approach to Go
Facial Expression Recognition Using Pseudo 3-D Hidden Markov Models
Multi-Dimensional Dependency-Tree Hidden Markov Models
Hierarchical models of object recognition in cortex
Towards end-to-end speech recognition with recurrent neural networks
Long short-term memory based recurrent neural network architectures for large vocabulary speech recognition
Show and Tell: A Neural Image Caption Generator
Show, attend and tell: Neural image caption generation with visual attention
On the properties of neural machine translation: Encoder-decoder approaches
Gated Feedback Recurrent Neural Networks
Learning language through pictures
Deep learning via hessian-free optimization
Learning recurrent neural networks with Hessian-free optimization
Training deep and recurrent networks with hessian-free optimization
Neural Turing machines
Mapping part-whole hierarchies into connectionist networks
Ask Me Anything: Dynamic Memory Networks for Natural Language Processing
A survey on the application of recurrent neural networks to statistical language modeling
Gradient calculations for dynamic recurrent neural networks: A survey
Learning meanings for sentences
Advances in optimizing recurrent networks
Bridging Long Time Lags by Weight Guessing and Long Short Term Memory
http://karpathy.github.io/2015/05/21/rnn-effectiveness/
A Novel Connectionist System for Unconstrained Handwriting Recognition
The Prefrontal Cortex: Executive and Cognitive Functions, book: chapter: Working memory and executive control
Learning continuous phrase representations and syntactic parsing with recursive neural networks
Joint Language and Translation Modeling with Recurrent Neural Networks
Deep visual-semantic alignments for generating image descriptions
Deep Captioning with Multimodal Recurrent Neural Networks (m-RNN)
Unsupervised learning of video representations using LSTMs
Connnectionist Speech Recognition: A Hybrid Approach
Probabilistic temporal reasoning
Learning the structure of dynamic probabilistic networks
An Introduction to the Theory of Point Processes: Volume I Elementary Theory and Methods, Second Edition
Continuous Time Bayesian Networks
Expectation Maximization and Complex Duration Distributions for Continuous Time Bayesian Networks
CT-NOR Representing and Reasoning About Events in Continuous Time
Modeling Events with Cascades of Poisson Processes
Poisson-Networks A Model for Structured Point Processes
A point process framework relating neural spiking activity to spiking history, neural ensemble, and extrinsic covariate effects
Credit assignment through time Alternatives to backpropagation
An efficient gradient-based algorithm for on-line training of recurrent network trajectories
The recurrent cascade-correlation learning algorithm
Comparing Hidden Markov Models and Long Short Term Memory Neural Networks for Learning Action Representations
A learning algorithm for continually running fully recurrent net works
A New LSTM Model by Introducing Biological Cell State
Phased LSTM Accelerating Recurrent Network Training for Long or Event-based Sequences
Incremental construction of LSTM recurrent neural network
Adaptive neural oscillator using continuoustime backpropagation learning
The Handbook of Brain Theory and Neural Networks (Stochastic approximation and neural network learning)
Scaling up spike-and-slab models for unsupervised feature learning
Generative Models for Discovering Sparse Distributed Representations
Generating Text with Recurrent Neural Networks
Exploring Models and Data for Image Question Answering
An exact mapping between the Variational Renormalization Group and Deep Learning
Neural Episodic Control
Towards Biologically Plausible Deep Learning
Distributional Smoothing with Virtual Adversarial Training
On distinguishability criteria for estimating generative models
Learning Representations by Recirculation
Estimation of non-normalized statistical models using score matching
Learning iterative image reconstruction in the neural abstraction pyramid
http://people.idsia.ch/~juergen/compressednetworksearch.html
https://www.youtube.com/watch?v=TFIMqt0yT2I
Simple Algorithmic Theory of Subjective Beauty, Novelty, Surprise, Interestingness, Attention, Curiosity, Creativity, Art, Science, Music, Jokes
books for RNN lab: https://www.reddit.com/r/MachineLearning/comments/2xcyrl/i_am_j%C3%BCrgen_schmidhuber_ama/cp5c0py/
Reinforcement Learning A Survey
http://people.idsia.ch/~juergen/rl.html
http://people.idsia.ch/~juergen/interest.html
http://people.idsia.ch/~juergen/creativity.html
http://people.idsia.ch/~juergen/unilearn.html
http://people.idsia.ch/~juergen/goedelmachine.html
http://people.idsia.ch/~juergen/oops.html
https://www.youtube.com/watch?v=VIRCybGgHts
Training Very Deep Networks
A Novel Connectionist System for Improved Unconstrained Handwriting Recognition
Dropout improves Recurrent Neural Networks for Handwriting Recognition
Fast and robust training of recurrent neural networks for offline handwriting recognition
Addressing the Rare Word Problem in Neural Machine Translation
TTS synthesis with bidirectional LSTM based recurrent neural networks
Multi-resolution linear prediction based features for audio onset detection with bidirectional LSTM neural networks
Dynamic Cortex Memory: Enhancing Recurrent Neural Networks for Gradient-Based Sequence Learning in book Artificial Neural Networks and Machine Learning – ICANN 2014
Inference and missing data
Missing data our view of the state of the art
David M Kreindler and Charles J Lumsden. The effects of the irregular sample and missing data in time series analysis. Nonlinear Dynamical Systems Analysis for the Behavioral Sciences Using Real Data, 2012
Wavelet variance analysis for gappy time series
Comparison of correlation analysis techniques for irregularly sampled time series
Multiple imputation using chained equations issues and guidance for practice
Pattern classification with missing data: a review
Strategies for Handling Missing Data in Electronic Health Record Derived Data
Deep Neural Networks for Acoustic Modeling in Speech Recognition The Shared Views of Four Research Groups
Optimal and Robust Estimation With an Introduction to Stochastic Control Theory (book)
Estimating or Propagating Gradients Through Stochastic Neurons for Conditional Computation
Recursive Bayesian Recurrent Neural Networks for Time-Series Modeling
Forecasting wind speed with recurrent neural networks
Training second-order recurrent neural networks using hints
Using Recurrent Artificial Neural Networks to Forecast Household Electricity Consumption
Recurrent policy gradients
Reinforced recurrent neural networks for multi-step-ahead flood forecasts
A generalized LSTM-like training algorithm for second-order recurrent neural networks
Real-Time Recurrent Neural State Estimation
Recurrent Network Models of Sequence Generation and Memory
Constructive training of recurrent neural networks using hybrid optimization
Recurrent neural network-based control strategy for battery energy storage in generation systems with intermittent renewable energy sources
Large scale recurrent neural network on GPU
Recognizing recurrent neural networks (rRNN) Bayesian inference for recurrent neural networks
Exchange rate forecasting using echo state networks for trading strategies
Tensorflow: Large-scale machine learning on heterogeneous distributed systems
The uncrowded window of object recognition
Early Visual Concept Learning with Unsupervised Deep Learning
InfoGAN Interpretable Representation Learning by Information Maximizing Generative Adversarial Nets
https://distill.pub/2017/feature-visualization/
On the computational power of neural nets
Time Series Analysis, Fourth Edition (book)
Grad-CAM: Visual Explanations from Deep Networks via Gradient-based Localization
Probabilistic machine learning and artificial intelligence
Batch Renormalization: Towards Reducing Minibatch Dependence in Batch-Normalized Models
Self-Normalizing Neural Networks
Mastering Chess and Shogi by Self-Play with a General Reinforcement Learning Algorithm
Net-Trim Convex Pruning of Deep Neural Networks with Performance Guarantee
Policy gradient methods for reinforcement learning with function approximation
Large scale distributed deep networks
Learning matrices and their applications
Pattern recognition by means of automatic analogue apparatus
The induction of dynamical recognizers
Learning Context-free Grammars Capabilities and Limitations of a Recurrent Neural Network with an External Stack Memory
Learning phrase representations using rnn encoder-decoder for statistical machine translation
Self-paced visual category discovery
Recurrent neural network based language model
A unified approach on fast training of feedforward and recurrent networks using EM algorithm
An overview of gradient descent optimization algorithms
Some methods of speeding up the convergence of iteration methods
Safe and Efficient Off-Policy Reinforcement Learning
Playing Atari with Deep Reinforcement Learning
Reinforcement learning, efficient coding, and the statistics of natural tasks
Efficient backprop
Micro-differential evolution: Diversity enhancement and a comparative study
Alopex: A correlation-based learning algorithm for feedforward and recurrent neural networks
Recurrent Convolutional Neural Network for Object Recognition
A simple way to initialize recurrent networks of rectified linear units
Improved transition-based parsing by modeling characters instead of words with lstms
Applying convolutional neural networks concepts to hybrid nn-hmm model for speech recognition
Learning natural language inference with lstm
Generative Image Modeling Using Spatial LSTMs
Empirical evaluation and combination of advanced language modeling techniques
Extensions of recurrent neural network language model
Generating text with recurrent neural networks
Lstm neural networks for language modeling
Connectionist temporal classification: labelling unsegmented sequence data with recurrent neural networks
A neural transducer
Survey on speech emotion recognition: Features, classification schemes, and databases
Adieu features? end-to-end speech emotion recognition using a deep convolutional recurrent network
Abandoning emotion classes-towards continuous emotion recognition with modelling of long-range dependencies
High-level feature representation using recurrent neural network for speech emotion recognition
Fast second order stochastic backpropagation for variational inference
Text-to-speech conversion with neural networks: A recurrent tdnn approach
Speech synthesis using artificial neural networks trained on cepstral coefficients
Unidirectional long short-term memory recurrent neural network with recurrent output layer for low-latency speech synthesis
Prosody contour prediction with long short-term memory, bi-directional, deep recurrent neural networks
Wavenet: A generative model for raw audio
A first look at music composition using lstm recurrent neural networks
Dag-recurrent neural networks for scene labeling
Quaddirectional 2d-recurrent neural networks for image labeling
Scene labeling with lstm recurrent neural networks
Pixel recurrent neural networks
Outrageously Large Neural Networks: The Sparsely-Gated Mixture-of-Experts Layer
Identification and control of dynamical systems using neural networks
https://www.oreilly.com/learning/introduction-to-local-interpretable-model-agnostic-explanations-lime
http://fxcmpy.tpq.io/00_quick_start.html
Python for Finance: Analyze Big Financial Data new version
https://www.wiley.com/en-gb/Advances+in+Financial+Machine+Learning-p-9781119482086
celery, dask, ray python lib
Gaussian processes for machine learning
Drawing connections for regression in deep NN, kernel methods and Gaussian processes. All methods are connected and can be derived
from each other.
Elements of Statistical Learning
Probability Theory: the Logic of Science
Generative adversarial nets
Variational inference with normalizing flows
Improving variational inference with inverse autoregressive flow
Variational inference for Monte Carlo objectives
IMPORTANCE WEIGHTED AUTOENCODERS
Missing values in nonlinear factor analysis
Training energy-based models for time-series imputation
Multi-prediction deep boltzmann machines
A deep and tractable density estimator
Generalized denoising auto-encoders as generative models