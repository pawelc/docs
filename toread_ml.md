1951 - A stochastic approximation method
1984 - Monte Carlo methods of inference for implicit statistical models
1986 - The Arithmetic of Differentiation
1997 - On bias, variance, 0/1 - loss, and the curse-of-dimensionality
1999 - Nonlinear independent component analysis: Existence and uniqueness results
2005 - Triangular transformations of measures
2006 - Gaussian processes for machine learning
2007 - A Kernel Method for the Two-Sample-Problem
2007 - An analysis of logistic models: Exponential family connections and online performance
2009 - Unlearning for better mixing
2011 - The Separation Plot: A New Visual Method for Evaluating the Fit of Binary Models
2012 - Python for Data Analysis
2016 - https://www.cs.ox.ac.uk/people/nando.defreitas/machinelearning/
2017 - UAI 2017 Tutorial: Shakir Mohamed & Danilo Rezende (https://www.youtube.com/watch?v=JrO5fSskISY, DeepGenModelsTutorial.pdf)
2017 - On Blackbox Backpropagation and Jacobian Sensing
2017 - Detecting Statistical Interactions from Neural Network Weights
2018 - The simple essence of automatic differentiation
2018 - Neural Sketch Learning for Conditional Program Generation
2019 - Exascale Deep Learning for Scientific Inverse Problems
2019 - Deep Learning with PyTorch
2019 - Static Automatic Batching In TensorFlow
2019 - https://github.com/khipu-ai/practicals-2019
2019 - Stanford CS330: Multi-Task and Meta-Learning, 2019 (https://www.youtube.com/watch?v=0rZtSwNOTQo&list=PLoROMvodv4rMC6zfYmnD7UG3LVvwaITY5)
2019 - A Review of Automatic Differentiation and its Efficient Implementationd
2019 - Compositional uncertainty in deep Gaussian processes
2020 - https://braininspired.co/podcast/
2020 - https://www.youtube.com/watch?v=BCiZc0n6COY&list=PLruBu5BI5n4aFpG32iMbdWoRVAA-Vcso6
2020 - http://mbmlbook.com/
2020 - Fair k-Means Clustering
2020 - Robust $k$-means++

Determining the degree of generalization using an incremental learning algorithm
Pattern Classification and Scene Analysis
No Free Lunch for Early Stopping
No Free Lunch for Noise Prediction
A Dozen Tricks with Multitask Learning
Analysis on Manifolds
Uncertainty estimation using fuzzy measures for multiclass classification
Monotone models for prediction in data mining
Multivariate decision trees with monotonicity constraints
RELIABLE INTEGRATION OF CONTINUOUS CONSTRAINTdS INTO EXTREME LEARNING MACHINES
Methods of Conjugate Gradients for Solving Linear Systems
TensorFlow Estimators Managing Simplicity vs. Flexibility in High-Level Machine Learning Frameworks
Bayesian Filtering and Smoothing
TFX: A TensorFlow-Based Production-Scale Machine Learning Platform
On the quantitative analysis of deep belief networks
Mixtures of Conditional Gaussian Scale Mixtures Applied to Multiscale Image Representations
Gaussian process networks
Evaluating probabilities under high-dimensional latent variable models
SHORTEN simple lossless and nearlossless waveform compression
Deep mixtures of factor analysers
Mixture of factor analyzers Matlab implementation (http://lear.inrialpes.fr/ verbeek/code)
Natural images, Gaussian mixtures and dead leaves
No More Pesky Learning Rate
Exploring the Limits of Weakly Supervised Pretraining
Evaluation and Selection of Biases in Machine Learning
The lack of a priori distinctions between learning algorithms
The need for biases in learning generalizations
Information Theory, Inference, and Learning Algorithms
Bayesian Reasoning and Machine Learning
Graphical Models for Machine Learning and Digital Communication
Machine learning: a probabilistic perspective
EM algorithms for ML factor analysis
Evaluation and selection of biases in machine learning
Maximum likelihood from incomplete data via the EM algorithm
Annealing between distributions by averaging moments
Learning multiple layers of features from tiny 
GTM the generative topographic mapping
Probabilistic Reasoning in Intelligent Systems
Causal feature selection
Random search for hyper-parameter optimization
Practical Bayesian optimization of machine learning algorithms
Improved Gaussian mixture density estimates using Bayesian penalty terms and netwoadamrk averaging
Linearly combining density estimators via stacking
Regression quantiles
Theoretical comparison between the Gini Index and Information Gain criteria
Optimization for Machine Learning
Optimization methods for large-scale machine learning
Accelerated training of conditional random fields with stochastic gradient methods
https://medium.com/deep-learning-turkey/google-colab-free-gpu-tutorial-e113627b9f5d
Learning to rank using gradient descent
Adaptivemixtures of local experts
Trees, Mixtures of Trees and Non-parametric Bayesian Learning
Probabilistic Networks and Expert Systems
Posterior Sampling When the Normalizing Constant is Unknown
Automatic choice of dimensionality for PCA
Differential geometry of curved exponential families-curvatures and information loss
Introduction to Stochastic Search and Optimization: Estimation, Simulation and Control
Large scale online learning
Probabilistic topic models
Learning the parts of objects by non-negative matrix factorization
Data Analysis Using Regression and MultilevelHierarchical Models
Dynamic topic models
Bayesian probabilistic matrix factorization using Markov chain Monte Carlo
Largescale feature learning with spike-and-slab sparse coding
Generalized spike-andslab priors for bayesian group feature selection using expectation propagation
Information processing in dynamical systems: Foundations of harmony theory
Decision Trees and Forests: A Probabilistic Perspective
Bayesian Learning in Probabilistic Decision Trees
Pachinko Allocation DAG-Structured Mixture Models of Topic Correlations
Bayesian exponential family PCA
Applying discrete PCA in data analysis
Scalable recommendation with poisson factorization
Evaluation methods for topic models
Collaborative filtering: A machine learning perspective
LETOR: Benchmark dataset for research on learning to rank for information retrieval
Learning to rank: from pairwise approach to listwise approach
Learning to rank with nonsmooth cost functions
A support vector method for multivariate performance measures
Cumulated gain-based evaluation of IR techniques
A comparison of numerical optimizers for logistic regression
The unified propagation and scaling algorithm
Iterative Scaling and Coordinate Descent Methods for Maximum Entropy Models
An introduction to conditional random fields for relational learning
Conditional random fields: Probabilistic models for segmenting and labeling sequence data
Discriminative training and maximum entropy models for statistical machine translation
Idiots Bayes Not So Stupid After All
Classification of Web Documents Using a Naive Bayes Method
An experimental comparison of naive Bayesian and keyword-based anti-spam filtering with personal e-mail messages
The EM algorithm in independent component analysis
Optimization with EM and Expectation-Conjugate-Gradient
Estimating the dimension of a model
Are two Classifiers performing equally A treatment using Bayesian Hypothesis Testing
Markov chain Monte Carlo in practice
Independent component analysis, a new concept
Learning sparse topographic representations with products of student-t distributions
Learning overcomplete representations
Energy-based models for sparse overcomplete representations
Extreme components analysis
Rate-coded restricted Boltzmann machines for face recognition
Mining associated text and images with dual-wing harmoniums
Products of hidden markov models
Recognizing hand-written digits using hierarchical products of experts
Restricted boltzmann machines for collaborative filtering
Inference for clustered data using the independence loglikelihood
https://blog.evjang.com/ <- nice blogs about ML
https://j-towns.github.io/2017/06/12/A-new-trick.html
https://github.com/renmengye/tensorflow-forward-ad/issues/2
https://datascience.stackexchange.com/questions/26792/difference-between-rmsprop-with-momentum-and-adam-optimizers
http://ruder.io/optimizing-gradient-descent/index.html
https://towardsdatascience.com/a-look-at-gradient-descent-and-rmsprop-optimizers-f77d483ef08b
Visualization of Tradeoff in Evaluation
A method for discovering the insignificance of ones best classifier and the unlearnability of a classification task
Receiver Operating Characteristic (ROC) Curves
The relationship between Precision-Recall and ROC curves
https://lukeoakdenrayner.wordpress.com/2018/01/07/the-philosophical-argument-for-using-roc-curves/
http://people.cs.bris.ac.uk/~flach/ICML04tutorial//
ROC curves in cost space
Cost curves An improved method for visualizing classifier performance
https://towardsdatascience.com/what-metrics-should-we-use-on-imbalanced-data-set-precision-recall-roc-e2e79252aeba
https://stats.stackexchange.com/questions/222558/classification-evaluation-metrics-for-highly-imbalanced-data
https://datascience.stackexchange.com/questions/28227/why-will-the-accuracy-of-a-highly-unbalanced-dataset-reduce-after-oversampling
https://www.tensorflow.org/guide/performance/overview
https://www.youtube.com/watch?v=Vly8xGnNiWs
https://www.youtube.com/watch?v=Ucp0TTmvqOE
Better mixing via deep representations
How auto-encoders could provide credit assignment in deep networks via target propagation
Independent component analysis: algorithms and applications
Learning the irreducible representations of commutative lie groups
Deep unsupervised learning using nonequilibrium thermodynamics
Colorful image colorization
Super-resolution with deep convolutional sufficient statistics
Stochastic gradient estimate variance in contrastive divergence and persistent contrastive divergence
A view of the em algorithm that justifies incremental, sparse, and other variants
Learning representations by backpropagating errors
Exploring the limits of language modeling
Deep generative image models using a laplacian pyramid of adversarial networks
Unsupervised representation learning with deep convolutional generative adversarial networks
Autoencoding beyond pixels using a learned similarity metric
An information-maximization approach to blind separation and blind deconvolution
Do Deep Generative Models Know What They Don't Know?
Vision as bayesian inference: analysis by synthesis?
Analysis-by-synthesis by learning to invert generative black boxes
A hierarchical latent variable encoder-decoder model for gen- erating dialogues
https://rise.cs.berkeley.edu/blog/michael-i-jordan-artificial-intelligence%e2%80%8a-%e2%80%8athe-revolution-hasnt-happened-yet/
https://github.com/rasbt/deeplearning-models
The Unreasonable Effectiveness of Data
Large-Scale Machine Learning at Twitter
https://github.com/tensorflow/tensor2tensor