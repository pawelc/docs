The Kanerva Machine: A Generative Distributed Memory
Learning Stochastic Recurrent Networks
Learning visual motion in recurrent neural networks
Modeling temporal dependencies in high-dimensional sequences: Application to polyphonic music generation and transcription
Bayesian Data Analysis Straight-line Fitting
Neural GPUs Learn Algorithms
Learning Wake-Sleep Recurrent Attention Models
Learning Structured Output Representation using Deep Conditional Generative Models
Learning to Predict by the Methods of Temporal Differences
Evolving Neural Turing Machines for Reward-based Learning
Scaling Memory-Augmented Neural Networks with Sparse Reads and Writes
Can Active Memory Replace Attention
Pointer networks
Hard attention:    
Show, Attend and Tell: Neural Image Caption Generation with Visual Attention
LIE-ACCESS NEURAL TURING MACHINES
Neural programmer: Inducing latent programs with gradient descent
Neural GPUs
Learning to Remember Rare Events
Evolutionary multi-objective generation of recurrent neural network ensembles for time series prediction
The Goldilocks Principle Reading Children's Books with Explicit Memory Representations
Towards ai-complete question answering a set of prerequisite toy tasks
Recurrent memory network for language modeling
Learning longer memory in recurrent neural networks
Large-scale Simple Question Answering with Memory Networks
Evaluating Prerequisite Qualities for Learning End-to-End Dialog Systems
Automatic Rule Extraction from Long Short Term Memory Networks
Neural Map Structured Memory for Deep Reinforcement Learning
Condensed Memory Networks for Clinical Diagnostic Inferencing
Frustratingly Short Attention Spans in Neural Language Modeling
Gated End-to-End Memory Networks
Dynamic Key-Value Memory Networks for Knowledge Tracing
Lie Access Neural Turing Machine
Attentive Memory Networks Efficient Machine Reading for Conversational Search
Recurrent Memory Addressing for describing videos
Dynamic Neural Turing Machine with Continuous and Discrete Addressing Schemes
Learning Operations on a Stack with Neural Turing Machines
Deep Multi-Task Learning with Shared Memory
A Theory of Sequence Indexing and Working Memory in Recurrent Neural Networks
Recurrent Memory Array Structures
Improving the Neural GPU Architecture for Algorithm Learning
Extensions and Limitations of the Neural GPU
Learning Efficient Algorithms with Hierarchical Attentive Memory
Reasoning with Memory Augmented Neural Networks for Language Comprehension
Deep Networks with Internal Selective Attention through Feedback Connections
Learning phrase representations using rnn encoder-decoder for statistical machine translation
A Multi-World Approach to Question Answering about Real-World Scenes based on Uncertain Input
Learning a recurrent visual representation for image caption generation
Stacked attention networks for image question answering
Teaching machines to read and comprehend
Attention and Augmented Recurrent Neural Networks https://distill.pub/2016/augmented-rnns
Match memory recurrent networks
Going deeper: Autonomous steering with neural memory networks
Memory-Augmented Neural Networks for Predictive Process Analytics
Gated Feedback Recurrent Neural Networks
Bayesian Recurrent Neural Networks
Recursive Bayesian Recurrent Neural Networks for Time-Series Modeling
https://en.wikipedia.org/wiki/Differentiable_neural_computer
https://www.reddit.com/r/MachineLearning/comments/5ebmdr/discussion_uncertainty_propagation_in_lstmbased/
https://openreview.net/forum?id=BkDB51WR-
Lstm recurrent networks learn simple context-free and context-sensitive languages
Memory Augmented Neural Networks with Wormhole Connections
Feedforward Sequential Memory Neural Networks without Recurrent Feedback
Cumulative distribution networks

Self-Delimiting Neural Networks
Optimal ordered problem solver
Applications of quantum inspired computational intelligence: a survey
Deep Learning for Time-Series Analysis
One-Shot Generalization in Deep Generative Models
One-shot Learning with Memory-Augmented Neural Networks
Cortical microcircuits as gated-recurrent neural networks
Learning to Diagnose with LSTM Recurrent Neural Networks
Recurrent generative adversarial networks for proximal learning and automated compressive image recovery
Generalization of deep neural networks for chest pathology classification in x-rays using generative adversarial networks
Speech recognition with missing data using recurrent neural nets
Modeling Missing Data in Clinical Time Series with RNNs
Doctor AI: Predicting Clinical Events via Recurrent Neural Networks
DeepCare A Deep Dynamic Memory Model for Predictive Medicine
Directly Modeling Missing Data in Sequences with RNNs Improved Classification of Clinical Time Series
Differential recurrent neural networks for action recognition
https://machinelearningmastery.com/promise-recurrent-neural-networks-time-series-forecasting/
Visualizing and Understanding Recurrent Networks (also video https://skillsmatter.com/skillscasts/6611-visualizing-and-understanding-recurrent-networks)
Framewise phoneme classiﬁcation with bidirectional LSTM and other neural network architectures
Training Recurrent Networks by Evolino
Evolving memory cell structures for sequence learning
Long Short-Term Memory Recurrent Neural Network Architectures for Large Scale Acoustic Modeling
Long Short-Term Memory in Recurrent Neural Networks
LSTM can Solve Hard Long Time Lag Problems
Gradient Flow in Recurrent Nets the Difficulty of Learning Long-Term Dependencies
Stock Price Prediction via Discovering Multi-Frequency Trading Patterns
Accelerating Recurrent Neural Networks A Memory-Efficient Approach
Learning compact recurrent neural networks
Real-time interactive sequence generation and control with Recurrent Neural Network ensembles
From Bayesian Sparsity to Gated Recurrent Nets
Recurrent Additive Networks
Translating videos to natural language using deep recurrent neural networks
Video description generation incorporating spatiotemporal features and a soft-attention mechanism
Sequence to Sequence -- Video to Text
Recurrent Models of Visual Attention
Multiple Object Recognition with Visual Attention
https://deepmind.com/blog/differentiable-neural-computers/
https://www.youtube.com/watch?v=steioHoiEms
https://github.com/deepmind/dnc
https://www.youtube.com/watch?v=QuvRWevJMZ4 - attention
Generative Adversarial Networks
Domain-Adversarial Neural Networks
Domain-Adversarial Training of Neural Networks
Learning Phrase Representations using RNN Encoder–Decoder for Statistical Machine Translation (this is about GRU)
Empirical evaluation of gated recurrent neural networks on sequence modeling
Depth-Gated LSTM
A clockwork RNN
A Long Short-Term Memory Recurrent Neural Network Framework for Network Traffic Matrix Prediction
Structural-RNN: Deep Learning on Spatio-Temporal Graphs
Adaptive Computation Time for Recurrent Neural Networks
Spatially Adaptive Computation Time for Residual Networks (https://www.youtube.com/watch?v=xp5lLiA-hA8)
Training recurrent networks online without backtracking
A tutorial on training recurrent neural networks, covering BPPT, RTRL, EKF and the "echo state network" approach
Decoupled Neural Interfaces using Synthetic Gradients
Curriculum Learning
Active Learning Literature Survey
Unifying Count-Based Exploration and Intrinsic Motivation
Automated Curriculum Learning for Neural Networks
https://github.com/salesforce/pytorch-qrnn
http://people.idsia.ch/~juergen/rnn.html
Learning to Control Fast-Weight Memories An Alternative to Dynamic Recurrent Networks
Extraction of rules from discrete-time recurrent neural networks
Learning Context Free Grammars Limitations of a Recurrent Neural Network with an External Stack Memory
A Connectionist Symbol Manipulator That Discovers the Structure of Context-Free Languages
Learning to coBayesian Recurrent Neural Networks
Recursive Bayesian Recurrent Neural Networks for Time-Series Modelingntrol fast-weight memories: An alternative to recurrent nets
Learning Precise Timing with LSTM Recurrent Networks
An introspective network that can learn to run its own weight change algorithm
Learning To Learn Using Gradient Descent
Learning to learn by gradient descent by gradient descent
http://people.idsia.ch/~juergen/metalearner.html
Sequential Constant Size Compressors for Reinforcement Learning
Sequence Labelling in Structured Domains with Hierarchical Recurrent Neural Networks
Learning Complex, Extended Sequences Using the Principle of History Compression
Evolving Neural Networks in Compressed Weight Space
https://github.com/openai/multiagent-competition
https://blog.openai.com/competitive-self-play/
http://people.idsia.ch/~juergen/optimalsearch.html
http://people.idsia.ch/~juergen/evolino.html
Driven by Compression Progress A Simple Principle Explains Essential Aspects of Subjective Beauty, Novelty, Surprise, Interestingness, Attention, Curiosity, Creativity, Art, Science, Music, Jokes
Resource-Bounded Machines are Motivated to be Effective, Efficient, and Curious
https://aeon.co/essays/how-close-are-we-to-creating-artificial-intelligence
https://www.icsi.berkeley.edu/icsi/events/2014/08/schmidhuber-rnn
https://blog.openai.com/competitive-self-play/
https://github.com/openai/multiagent-competition
https://r2rt.com/styles-of-truncated-backpropagation.html
Statistical Language Models based on Neural Networks
On Multiplicative Integration with Recurrent Neural Networks
Layer Normalization
https://r2rt.com/recurrent-neural-networks-in-tensorflow-ii.html
Learning Long-Term Dependencies with Gradient Descent is Difficult.
Protein Secondary Structure Prediction with Long Short Term Memory Networks
An Efficient Approach for Assessing Hyperparameter Importance
Generalized Functional ANOVA Diagnostics for High-Dimensional Functions of Dependent Variables
Recurrent Highway Networks (https://github.com/julian121266/RecurrentHighwayNetworks)
Highway and Residual Networks learn Unrolled Iterative Estimation
DropIn: Making Reservoir Computing Neural Networks Robust to Missing Inputs by Dropout
Multi-directional Recurrent Neural Networks A Novel Method for Estimating Missing Data
Explaining Recurrent Neural Network Predictions in Sentiment Analysis
E-RNN Entangled Recurrent Neural Networks for Causal Prediction
Recurrent neural network based language model
Context dependent recurrent neural network language model
Deep Computational Phenotyping
An overview and comparative analysis of Recurrent Neural Networks for Short Term Load Forecasting
Predicting Remaining Useful Life using Time Series Embeddings based on Recurrent Neural Networks
m-TSNE: A Framework for Visualizing High-Dimensional Multivariate Time Series
Grounded Recurrent Neural Networks
Second-order training for recurrent neural networks without teacher-forcing
Modeling Progression Free Survival in Breast Cancer with Tensorized Recurrent Neural Networks and Accelerated Failure Time Models
End-to-end attention-based large vocabulary speech recognition
Attention-Based Models for Speech Recognition
Sequence to Sequence Learning with Neural Networks
Mind’s Eye: A Recurrent Visual Representation for Image Caption Generation
Time Series for Macroeconomics and Finance
Scheduled Sampling for Sequence Prediction with Recurrent Neural Networks
An Actor-Critic Algorithm for Sequence Prediction
Search-based structured prediction
A Reduction of Imitation Learning and Structured Prediction to No-Regret Online Learning
How (not) to Train your Generative Model: Scheduled Sampling, Likelihood, Adversary?
Zoneout Regularizing RNNs by Randomly Preserving Hidden Activations
Recurrent neural networks with limited numerical precision
Batch normalized recurrent neural networks
Attention is all you need
Banishing the homunculus: making working memory work
Continuous attractors and oculomotor control
Expressive power of recurrent neural networks
https://arxiv.org/find/cs/1/au:+Fulcher_B/0/1/0/all/0/1
https://github.com/openai/blocksparse
Distilling a Neural Network Into a Soft Decision Tree
Bengio, Y., Louradour, J., Collobert, R. & Weston, J. Curriculum learning
Overcoming catastrophic forgetting in neural networks
Memory-based neural networks for robot learning
Prediction with a Short Memory
Can recurrent neural networks warp time?
Building machines that learn and think like people
Matching Networks for One Shot Learning
Learning Simple Algorithms from Examples
Meta-Learning with Memory-Augmented Neural Networks
Feedforward Sequential Memory Networks: A New Structure to Learn Long-term Dependency
Hierarchical Memory Networks
Memory-augmented Neural Machine Translation
LSTM with working memory
Learning to Generate with Memory
Active One-shot Learning
Position-based Content Attention for Time Series Forecasting with Sequence-to-sequence RNNs
Self-paced learning for latent variable models
Delving into adversarial attacks on deep policies
Kalman filters improve lstm network performance in problems unsolvable by traditional recurrent nets
The Future of Memory Remembering, Imagining, and the Brain
Is the brain a good model for machine intelligence
Evidence integration in model-based tree search
Artificial intelligence Deep neural reasoning
Kalman filtering and neural networks
Training recurrent networks using the extended kalman filter
An evolutionary algorithm that constructs recurrent neural networks
Evolutionary optimization of long short-term memory neural network language model
Long Short-Term Memory Over Tree Structures
Differential recurrent neural networks for action recognition
Semantic object parsing with local-global long short-term memory
Lstm time and frequency recurrence for automatic speech recognition
Convolutional lstm network: A machine learning approach for precipitation nowcasting
Unitary evolution recurrent neural networks
Gated Orthogonal Recurrent Units: On Learning to Forget
Improving neural networks with dropout
Rnndrop: A novel dropout for rnns in asr
Recurrent dropout without memory loss
Regularizing rnns by stabilizing activations
PRNN Recurrent Neural Network with Persistent Memory
Cascade Dynamics Modeling with Attention-based Recurrent Neural Network
Attention-based Mixture Density Recurrent Networks for History-based Recommendation
a learning algorithm for continually running fully recurrent neural networks
Nonlinear Statistical Models
Concrete problems in ai safety
Time-series Extreme Event Forecasting with Neural Networks at Uber
A neural probabilistic language model
Distilling the Knowledge in a Neural Network
Inserting rules into recurrent neural networks
Rule refinement with recurrent neural networks
On Learning to Think Algorithmic Information Theory for Novel Combinations of Reinforcement Learning Controllers and Recurrent Neural World Models
The time dimension of neural network models
Learning Sequence Representations
Learning Algorithms from Data
First-pass large vocabulary continuous speech recognition using bi-directional recurrent dnns
Recurrent Ladder Networks
Recurrent continuous translation models
Recurrent Memory Networks for Language Modeling
Multiplicative LSTM for sequence modelling
Optimizing Performance of Recurrent Neural Networks on GPUs
Interpretable Structure-Evolving LSTM
Neural Program Lattices
Improved TDNNs using Deep Kernels and Frequency Dependent Grid-RNNs
Nested LSTMs
Deep Neural Architectures for Algorithms and Sequential Data
Quasi-Recurrent Neural Networks
Mechanisms for sentence processing
Context-free parsing in connectionist networks
A recurrent network that performs a context-sensitive prediction task
A recurrent neural network that learns to count
Toward a connectionist model of recursion in human linguistic performance
Fractal encoding of context-free grammars in connectionist networks
Context-free and context-sensitive dynamics in recurrent neural networks
Generalization of backpropagation with application to a recurrent gas market model
https://www.basicbooks.com/titles/judea-pearl/the-book-of-why/9780465097609/
https://www.quantamagazine.org/to-build-truly-intelligent-machines-teach-them-cause-and-effect-20180515/
https://medium.com/applied-data-science/how-to-build-your-own-alphazero-ai-using-python-and-keras-7f664945c188
http://colah.github.io/posts/2015-08-Understanding-LSTMs/
https://medium.com/@aidangomez/the-neural-turing-machine-79f6e806c0a1
https://blog.aidangomez.ca/2016/04/17/Backpropogating-an-LSTM-A-Numerical-Example/
https://www.reddit.com/r/MachineLearning/comments/4xnuv2/what_is_the_general_belief_on_value_of_neural/
https://www.reddit.com/r/MachineLearning/comments/64lkry/d_explanation_of_deepminds_neural_turing_machine/
https://discuss.pytorch.org/t/neural-turing-machines-ntm-implementation/8276
https://www.quora.com/What-is-a-neural-Turing-machine
https://summerofcode.withgoogle.com/archive/2017/projects/6637623116300288/
https://stats.stackexchange.com/questions/241286/how-are-controllers-attached-to-read-write-heads-in-neural-turing-machines
https://trollheaven.wordpress.com/2017/12/15/neural-turing-machine/
A Novel Fractional Gradient-Based Learning Algorithm for Recurrent Neural Networks
Tree Memory Networks for Modelling Long-term Temporal Dependencies
On the memory properties of recurrent neural models
Divide and Conquer Networks
DeepCoder: Learning to Write Programs
Recurrent Neural Network for Text Classification with Multi-Task Learning
Tracking the World State with Recurrent Entity Networks
People:
http://www.cs.toronto.edu/~graves/
http://www.cs.toronto.edu/~ilya/
http://www0.cs.ucl.ac.uk/staff/d.silver/web/Home.html
https://people.eecs.berkeley.edu/~pabbeel/
http://www-etud.iro.umontreal.ca/~boulanni/
http://people.idsia.ch/~juergen/
Software:
https://github.com/fchollet/keras
https://github.com/karpathy/neuraltalk
Video:
http://cs231n.stanford.edu/
https://www.youtube.com/watch?v=xKt21ucdBY0
https://www.youtube.com/playlist?list=PLZHQObOWTQDPD3MizzM2xVFitgF8hE_ab
http://cs224d.stanford.edu/syllabus.html
Some other papers maybe worth reading
Learning to count without a counter A case study of dynamics and activation landscapes in recurrent networks
Recurrent Neural Networks Can Learn to Implement Symbol-Sensitive Counting
Connectionist Temporal Classification: Labelling Unsegmented Sequence Data with Recurrent Neural Networks
Multi-Dimensional Recurrent Neural Networks
Parallel Multi-Dimensional LSTM, With Application to Fast Biomedical Volumetric Image Segmentation
The Principled Design of Large-scale Recursive Neural Network Architectures–DAG-RNNs and the Protein Structure Prediction Problem
How to construct deep recurrent neural networks
TRAINING A NEURAL NETWORK WITH A FINANCIAL CRITERION RATHER THAN A PREDICTION CRITERION
Global optimization of a neural network-hidden Markov model hybrid
Recurrent Backpropagation and the Dynamical Approach to Adaptive Neural Computation
BPS: a learning algorithm for capturing the dynamical nature of speech
Robust speech recognition based on joint model and feature space optimization of hidden Markov models
Connectionist Viterbi training: a new hybrid method for continuous speech recognition
Word recognition using hidden control neural architecture
Links between Markov models and multilayer perceptrons
Connectionist Speech Recognition. A Hybrid Approach (book)
A comparison of hybrid HMM architecture using global discriminating training
Alpha-nets A recurrent ‘neural’ network architecture with a hidden Markov model interpretation
Continuous speech recognition using multilayer perceptrons with hidden Markov models
Continuous speech recognition by connectionist statistical methods
Context-dependent connectionist probability estimation in a hybrid hidden Markov model-neural net speech recognition system
Speech recognition using deep neural network - recent trends
An application of recurrent nets to phone probability estimation
A speech recognition method based on the sequential multi-layer perceptrons
New discriminative training algorithms based on the generalized probabilistic descent method
Speech recognition using neural networks with forward-backward probability generated targets
Non-linear input transformations for discriminative HMMs
Hidden neural networks: a framework for HMM/NN hybrids
Maximum mutual information neural networks for hybrid connectionist-HMM speech recognition systems
Something about TDNN
Finding structure in time
Deep, Convolutional, and Recurrent Models for Human Activity Recognition using Wearables
Financial Market Applications of Learning from Hints
Including Hints in Training Neural Nets
Sparse Kalman Filtering Approaches to Covariance Estimation from High Frequency Data in the Presence of Jumps
Generalization and network design strategies
Modularity and scaling in large phonemic neural networks
Articial Neural Networks and their Application to Sequence Recognition
Tangent prop - A formalism for specifying selected invariances in an adaptive network
Re-Sign: Re-Aligned End-to-End Sequence Modelling with Deep Recurrent CNN-HMMs
Unified integration of explicit knowledge and learning by example in recurrent networks
Programmable execution of multi-layered networks for automatic speech recognition
Phoneme Recognition Using Time Delay Neural Networks
Boosted Backpropagation Learning for Training Deep Modular Networks
Identifying and attacking the saddle point problem in high-dimensional non-convex
optimization
Big Neural Networks Waste Capacity
An empirical evaluation of recurrent network architectures
Delving Deep into Rectifiers: Surpassing Human-Level Performance on ImageNet Classification
Natural Neural Networks
On the diﬃculty of training Recurrent Neural Networks
From Machine Learning to Machine Reasoning 
Natural Language Processing (almost) from Scratch
Improving Stochastic Gradient Descent with Feedback
Primal-dual subgradient methods for convex problems (how to make models sparse)
Ad Click Prediction: a View from the Trenches (how to make models sparse), look at FTRLOptimizer in TensorFlow
Dropout: A Simple Way to Prevent Neural Networks from Overﬁtting
A theoretically grounded application of dropout in recurrent neural networks
Revisiting Distributed Synchronous SGD
https://petewarden.com/2016/05/03/how-to-quantize-neural-networks-with-tensorflow/
https://en.wikipedia.org/wiki/Xgboost
End-to-end people detection in crowded scenes
Fully Convolutional Networks for Semantic Segmentation
Inception-v4, Inception-ResNet and the Impact of Residual Connections on Learning
Unit Tests for Stochastic Optimization
https://github.com/tensorflow/tensorflow/blob/r0.10/tensorflow/examples/tutorials/deepdream/deepdream.ipynb
https://magenta.tensorflow.org/
A Comparative Study of the Performance of HMM, DNN, and RNN based Speech Synthesis Systems Trained on Very Large Speaker-Dependent Corpora
Rethinking the Inception Architecture for Computer Vision
How transferable are features in deep neural networks
Global continuation for distance geometry problems
A Theoretical Analysis of Optimization by Gaussian Continuation
Neural network learning control of robot manipulators using gradually increasing task difficulty
Recurrent Neural Network Regularization
LSTM A Search Space Odyssey
https://www.tensorflow.org/tutorials/seq2seq
https://www.tensorflow.org/tutorials/word2vec
http://colah.github.io/posts/2014-07-NLP-RNNs-Representations/
http://ruder.io/word-embeddings-1/
On Using Very Large Target Vocabulary for Neural Machine Translation
Long Short-Term Memory-Networks for Machine Reading
PatternNet and PatternLRP Improving the interpretability of neural networks
EXPLAINING AND HARNESSING ADVERSARIAL EXAMPLES
Deep Neural Networks are Easily Fooled: High Confidence Predictions for Unrecognizable Images
https://medium.com/merantix/picasso-a-free-open-source-visualizer-for-cnns-d8ed3a35cfc5
https://github.com/merantix/picasso
A Theoretical Analysis of Feature Pooling in Visual Recognition
Ask the locals: multi-way local pooling for image recognition
Beyond spatial pyramids: Receptive ﬁeld learning for pooled image features
Convolutional Sequence to Sequence Learning
Convolutional Recurrent Neural Networks: Learning Spatial Dependencies for Image Representation
Emergence of Complex-Like Cells in a Temporal Product Network with Local Receptive Fields
Multidimensional, Downsampled Convolution for Autoencoders
Perception in chess

Contractive Auto-Encoders: Explicit Invariance During Feature Extraction
Stacked Convolutional Auto-Encoders for Hierarchical Feature Extraction
GSNs: Generative Stochastic Networks
Winner-Take-All Autoencoders
Semantic Hashing
CNN Based Hashing for Image Retrieval
Recurrent Convolutional Neural Networks for Scene Parsing
From image-level to pixel-level labeling with convolutional networks
Joint training of a convolutional network and a graphical model for human pose estimation
Deep learning of invariant spatio-temporal features from video
Mechanisms underlying visual object recognition
Learning where to attend with deep architectures for image tracking
The development of the time-delay neural network architecture for speech recognition
Phoneme recognition using time-delay neural networks
A Time-Delay Neural Network Architecture for Isolated Word Recognition
Turing computability with neural nets
Computation Beyond the Turing Limit
On the Computational Power of Neural Nets
Turing machines are recurrent neural networks
https://www.oreilly.com/ideas/reinforcement-learning-for-complex-goals-using-tensorflow
https://www.youtube.com/watch?v=PwOnsT2UW5o
Multi-digit number recognition from Street View imagery using deep convolutional neural networks
Bidirectional recurrent neural networks
On Supervised Learning from Sequential Data With Applications for Speech Recognition
Sequence Learning lectures (book) -  Bidirectional Dynamics for Protein Secondary Structure Prediction
Capturing Long-term Dependencies for Protein Secondary Structure Prediction
Bidirectional Long Short-Term Memory Networks for Predicting the Subcellular Localization of Eukaryotic Proteins
Experiments on Learning by Back Propagation
Offline handwriting recognition with multidimensional recurrent neural networks
Unconstrained on-line handwriting recognition with recurrent neural networks
Speech recognition with deep recurrent neural networks Graves
Exploiting the past and the future in protein secondary structure prediction
ReNet: A recurrent neural network based alternative to convolutional networks
Markovian Models for Sequential Data
Probable Networks and Plausible Predictions - a Review of Practical Bayesian Methods for Supervised Neural Networks
Fast Model-based Protein Homology Detection without Alignment
Fast Curvature Matrix-Vector Products for Second-Order Gradient Descent
An Analysis of Noise in Recurrent Neural Networks: Convergence and Generalization
A comparison of preprocessors for the cambridge recurrent error propagation network speech recognition system
Learning Long-Term Dependencies in NARX Recurrent Neural Networks
Learning long-term dependencies is not as diﬃcult with NARX recurrent neural networks
Induction of Multiscale Temporal Structure
Finding temporal structure in music: blues improvisation with LSTM recurrent networks
Reinforcement Learning with Long Short-Term Memory
A Novel Approach to On-Line Handwriting Recognition Based on Bidirectional Long Short-Term Memory Networks
Modeling systems with internal state using evolino
Experiments on the Implementation of Recurrent Neural Networks for Speech Phone Recognition 
Rapid Retraining on Speech Data with LSTM Recurrent Networks
Introduction to the Special Issue on Meta-Learning
Hierarchical Recurrent Neural Networks for Long-Term Dependencies
Discovering multiscale dynamical features with hierarchical Echo State Networks
Recursive distributed representations
From machine learning to machine reasoning
On the eﬃcient classiﬁcation of data structures by neural networks
A general framework for adaptive processing of data structures
Dynamic pooling and unfolding recursive autoencoders for paraphrase detection
Semi-supervised recursive autoencoders for predicting sentiment distributions
Recursive deep models for semantic compositionality over a sentiment treebank
Parsing Natural Scenes and Natural Language with Recursive Neural Networks
Large scale image annotation: learning to rank with joint word-image embeddings
Bifurcations of Recurrent Neural Networks in Gradient Descent Learning
Random walks: Training very deep nonlinear feed-forward networks with smart initialization
On the importance of initialization and momentum in deep learning
Artiﬁcial Neural Networks and their Application to Sequence Recognition
Optimization and applications of echo state networks with leakyintegrator neurons
Bidirectional LSTM Networks for Improved Phoneme Classification and Recognition
Connectionist probability estimators in HMM speech recognition
LeRec: a NN/HMM hybrid for on-line handwriting recognition
Global Optimization of a Neural Network{Hidden Markov Model Hybrid
A new training algorithm for hybrid HMM/ANN speech recognition systems
Estimation of global posteriors and forward-backward training of hybrid HMM/ANN systems
Reading checks with multilayer graph transformer networks
Gradient-Based Learning Applied to Document Recognition
Graph Transformer Networks for Image Recognition
Speaker-Adaptation for Hybrid HMM-ANN Continuous Speech Recognition System
Forward-Backward Retraining of Recurrent Neural Networks
A Neural Network Based, Speaker Independent, Large Vocabulary, Continuous Speech Recognition System: the Wernicke Project
Large Margin Hidden Markov Models for Automatic Speech Recognition
Capacity and complexity of HMM duration modeling techniques
Neural network design for J function approximation in dynamic programming
Modular DAG–RNN Architectures for Assembling Coarse Protein Structures
Supervised neural networks for the classification of structures
Recurrent networks for structured data – A unifying approach and its properties
A Scalable Machine Learning Approach to Go
Facial Expression Recognition Using Pseudo 3-D Hidden Markov Models
Multi-Dimensional Dependency-Tree Hidden Markov Models
Hierarchical models of object recognition in cortex
Towards end-to-end speech recognition with recurrent neural networks
Long short-term memory based recurrent neural network architectures for large vocabulary speech recognition
Show and Tell: A Neural Image Caption Generator
On the properties of neural machine translation: Encoder-decoder approaches
Learning language through pictures
Learning recurrent neural networks with Hessian-free optimization
Training deep and recurrent networks with hessian-free optimization
Neural Turing machines
Mapping part-whole hierarchies into connectionist networks
A survey on the application of recurrent neural networks to statistical language modeling
Gradient calculations for dynamic recurrent neural networks: A survey
Learning meanings for sentences
Advances in optimizing recurrent networks
Bridging Long Time Lags by Weight Guessing and Long Short Term Memory
http://karpathy.github.io/2015/05/21/rnn-effectiveness/
A Novel Connectionist System for Unconstrained Handwriting Recognition
The Prefrontal Cortex: Executive and Cognitive Functions, book: chapter: Working memory and executive control
An Introduction to the Theory of Point Processes: Volume I Elementary Theory and Methods, Second Edition
Continuous Time Bayesian Networks
Expectation Maximization and Complex Duration Distributions for Continuous Time Bayesian Networks
CT-NOR Representing and Reasoning About Events in Continuous Time
Modeling Events with Cascades of Poisson Processes
Poisson-Networks A Model for Structured Point Processes
A point process framework relating neural spiking activity to spiking history, neural ensemble, and extrinsic covariate effects
Credit assignment through time Alternatives to backpropagation
An efficient gradient-based algorithm for on-line training of recurrent network trajectories
The recurrent cascade-correlation learning algorithm
Comparing Hidden Markov Models and Long Short Term Memory Neural Networks for Learning Action Representations
A learning algorithm for continually running fully recurrent net works
A New LSTM Model by Introducing Biological Cell State
Phased LSTM Accelerating Recurrent Network Training for Long or Event-based Sequences
Incremental construction of LSTM recurrent neural network
Adaptive neural oscillator using continuoustime backpropagation learning
The Handbook of Brain Theory and Neural Networks (Stochastic approximation and neural network learning)
Generative Models for Discovering Sparse Distributed Representations
Generating Text with Recurrent Neural Networks
Exploring Models and Data for Image Question Answering
Neural Episodic Control
Towards Biologically Plausible Deep Learning
On distinguishability criteria for estimating generative models
Learning Representations by Recirculation
Learning iterative image reconstruction in the neural abstraction pyramid
http://people.idsia.ch/~juergen/compressednetworksearch.html
https://www.youtube.com/watch?v=TFIMqt0yT2I
Simple Algorithmic Theory of Subjective Beauty, Novelty, Surprise, Interestingness, Attention, Curiosity, Creativity, Art, Science, Music, Jokes
books for RNN lab: https://www.reddit.com/r/MachineLearning/comments/2xcyrl/i_am_j%C3%BCrgen_schmidhuber_ama/cp5c0py/
Reinforcement Learning A Survey
http://people.idsia.ch/~juergen/rl.html
http://people.idsia.ch/~juergen/interest.html
http://people.idsia.ch/~juergen/creativity.html
http://people.idsia.ch/~juergen/unilearn.html
http://people.idsia.ch/~juergen/goedelmachine.html
http://people.idsia.ch/~juergen/oops.html
https://www.youtube.com/watch?v=VIRCybGgHts
Training Very Deep Networks
A Novel Connectionist System for Improved Unconstrained Handwriting Recognition
Dropout improves Recurrent Neural Networks for Handwriting Recognition
Fast and robust training of recurrent neural networks for offline handwriting recognition
Addressing the Rare Word Problem in Neural Machine Translation
TTS synthesis with bidirectional LSTM based recurrent neural networks
Multi-resolution linear prediction based features for audio onset detection with bidirectional LSTM neural networks
Dynamic Cortex Memory: Enhancing Recurrent Neural Networks for Gradient-Based Sequence Learning in book Artificial Neural Networks and Machine Learning – ICANN 2014
Inference and missing data
Missing data our view of the state of the art
David M Kreindler and Charles J Lumsden. The effects of the irregular sample and missing data in time series analysis. Nonlinear Dynamical Systems Analysis for the Behavioral Sciences Using Real Data, 2012
Wavelet variance analysis for gappy time series
Comparison of correlation analysis techniques for irregularly sampled time series
Multiple imputation using chained equations issues and guidance for practice
Pattern classification with missing data: a review
Strategies for Handling Missing Data in Electronic Health Record Derived Data
Optimal and Robust Estimation With an Introduction to Stochastic Control Theory (book)
Estimating or Propagating Gradients Through Stochastic Neurons for Conditional Computation
Forecasting wind speed with recurrent neural networks
Training second-order recurrent neural networks using hints
Using Recurrent Artificial Neural Networks to Forecast Household Electricity Consumption
Recurrent policy gradients
Reinforced recurrent neural networks for multi-step-ahead flood forecasts
A generalized LSTM-like training algorithm for second-order recurrent neural networks
Real-Time Recurrent Neural State Estimation
Recurrent Network Models of Sequence Generation and Memory
Constructive training of recurrent neural networks using hybrid optimization
Recurrent neural network-based control strategy for battery energy storage in generation systems with intermittent renewable energy sources
Large scale recurrent neural network on GPU
Recognizing recurrent neural networks (rRNN) Bayesian inference for recurrent neural networks
Exchange rate forecasting using echo state networks for trading strategies
Tensorflow: Large-scale machine learning on heterogeneous distributed systems
The uncrowded window of object recognition
InfoGAN Interpretable Representation Learning by Information Maximizing Generative Adversarial Nets
https://distill.pub/2017/feature-visualization/
On the computational power of neural nets
Time Series Analysis, Fourth Edition (book)
Grad-CAM: Visual Explanations from Deep Networks via Gradient-based Localization
Probabilistic machine learning and artificial intelligence
Batch Renormalization: Towards Reducing Minibatch Dependence in Batch-Normalized Models
Self-Normalizing Neural Networks
Mastering Chess and Shogi by Self-Play with a General Reinforcement Learning Algorithm
Net-Trim Convex Pruning of Deep Neural Networks with Performance Guarantee
Policy gradient methods for reinforcement learning with function approximation
Large scale distributed deep networks
Learning matrices and their applications
Pattern recognition by means of automatic analogue apparatus
The induction of dynamical recognizers
Discrete recurrent neural networks for grammatical inference
Self-paced visual category discovery
Recurrent neural network based language model
An overview of gradient descent optimization algorithms
Some methods of speeding up the convergence of iteration methods
Safe and Efficient Off-Policy Reinforcement Learning
Playing Atari with Deep Reinforcement Learning
Reinforcement learning, efficient coding, and the statistics of natural tasks
Micro-differential evolution: Diversity enhancement and a comparative study
Alopex: A correlation-based learning algorithm for feedforward and recurrent neural networks
Recurrent Convolutional Neural Network for Object Recognition
A simple way to initialize recurrent networks of rectified linear units
Improved transition-based parsing by modeling characters instead of words with lstms
Applying convolutional neural networks concepts to hybrid nn-hmm model for speech recognition
Learning natural language inference with lstm
Empirical evaluation and combination of advanced language modeling techniques
Extensions of recurrent neural network language model
Generating text with recurrent neural networks
Lstm neural networks for language modeling
Connectionist temporal classification: labelling unsegmented sequence data with recurrent neural networks
A neural transducer
Survey on speech emotion recognition: Features, classification schemes, and databases
Adieu features? end-to-end speech emotion recognition using a deep convolutional recurrent network
Abandoning emotion classes-towards continuous emotion recognition with modelling of long-range dependencies
High-level feature representation using recurrent neural network for speech emotion recognition
Text-to-speech conversion with neural networks: A recurrent tdnn approach
Speech synthesis using artificial neural networks trained on cepstral coefficients
Unidirectional long short-term memory recurrent neural network with recurrent output layer for low-latency speech synthesis
Prosody contour prediction with long short-term memory, bi-directional, deep recurrent neural networks
A first look at music composition using lstm recurrent neural networks
Dag-recurrent neural networks for scene labeling
Quaddirectional 2d-recurrent neural networks for image labeling
Scene labeling with lstm recurrent neural networks
Outrageously Large Neural Networks: The Sparsely-Gated Mixture-of-Experts Layer
Identification and control of dynamical systems using neural networks
http://fxcmpy.tpq.io/00_quick_start.html
Python for Finance: Analyze Big Financial Data new version
https://www.wiley.com/en-gb/Advances+in+Financial+Machine+Learning-p-9781119482086
celery, dask, ray python lib
Drawing connections for regression in deep NN, kernel methods and Gaussian processes. All methods are connected and can be derived
from each other.
Elements of Statistical Learning
Missing values in nonlinear factor analysis
Training energy-based models for time-series imputation
Generalized denoising auto-encoders as generative models
A unifying review of linear gaussian models
A new approach to linear filtering and prediction problems
Predictive representations of state
Closing the learning planning loop with predictive state representations
An online spectral learning algorithm for partially observable nonlinear dynamical systems
Supervised learning for dynamical system learning
A hilbert space embedding for distributions
Theory of reproducing kernels
Hilbert space embeddings of predictive state representations
A hmm-based pre-training approach for sequential data
Random features for large-scale kernel machines
Predictive State Recurrent Neural Networks
Introduction to information retrieval
Hyperdimensional computing An introduction to computing in distributed representation with high-dimensional random vectors
CPU versus GPU: which can perform matrix computation faster—performance comparison for basic linear algebra subprograms
Neural Machine Translation in Linear Time
Recursive Neural Networks Can Learn Logical Semantics
A Distributed Representation of Temporal Context
A bayesian analysis of dynamics in free recall
Random Forests
Hogwild: A lock-free approach to parallelizing stochastic gradient descent
Using prior knowledge in a nnpda to learn context-free languages
Designing a counter: Another case study of dynamics and activation landscapes in recurrent networks
Beyond prediction: A framework for inference with variational approximations in mixture models
A Roadmap Towards Machine Intelligence
Learning to Optimize
Inferring and Executing Programs for Visual Reasoning
End-to-end Differentiable Proving
Learning Explanatory Rules from Noisy Data
AP: Artificial Programming
Learning with marginalized corrupted features
Neural Networks and the Bias-Variance Dilemma
The Lack of A Priori Distinctions Between Learning Algorithms
Feasibility of using Adaptive Logic Networks to Predict Compressor Unit Failure