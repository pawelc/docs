Inference, Sampling, and Learning in Copula Cumulative Distribution Networks (with code 
https://github.com/stefanwebb/cumulativenet)
https://www.youtube.com/watch?v=dkKRpPa_I_o
Copula Bayesian Networks
Probability, Random Variables and Stochastic Processes
Learning with tree-averaged densities and distributions
Copulas in machine learning
The pseudo-marginal approach for efficient Monte Carlo computations
Vines: a new graphical model for dependent random variables
Factorial mixture of Gaussians and the marginal independence model
Posterior sampling when the normalising constant is unknown
Probabilistic supervised learning
Predictive Independence Testing, Predictive Conditional Independence Testing, and Predictive Graphical Modelling
Modelling Competitive Sports Bradley-Terry-Elo Models for Supervised and On-Line Learning of Paired Competition Outcomes
How Neural Nets Work
Capabilities of three-layered perceptrons
There exists a neural network that does not make avoidable mistakes
Theory of the backpropagation neural network
Probability and Measure
Approximation by superpositions of a sigmoidal function

High-dimensional probability estimation with deep density models
Variational inference with normalizing flows
NICE: Non-linear independent components estimation
Improved variational inference with inverse autoregressive flow
Variational lossy autoencoder
Masked autoregressive flow for density estimation
MADE Masked Autoencoder for Distribution Estimation
Parallel wavenet: Fast high-fidelity speech synthesis
Density estimation using Real NVP
Pixel recurrent neural networks
Neural Ordinary Differential Equations
ChauffeurNet: Learning to Drive by Imitating the Best and Synthesizing the Worst
Learnable explicit density for continuous latent space and variational inference <- demonstrates general universal representational capability
of inverse autoregressive transformations
Maximum entropy flow networks
Multiplicative normalizing flows for variational bayesian neural networks
Bayesian hypernetworks
A-NICE-MC: Adversarial Training for MCMC
Improving variational auto-encoders using convex combination linear inverse autoregressive flow
Normalizing flows on riemannian manifolds
Early stopping as nonparametric variational inference
Sylvester normalizing flows for variational inference
Transformation Autoregressive Networks
A characterization of the Dirichlet distribution through global and local parameter independence
A note on pseudolikelihood constructed from marginal densities
On composite marginal likelihoods
Fitting and testing vast dimensional time-varying covariance models
On the Use of Neural Networks in the Analysis of Nonlinear Systems Realization, Approximation, and Feedback Control
Bivariate Logistic Distributions
Deep belief networks are compact universal approximators
Refinements of universal approximation results for deep belief networks and restricted Boltzmann machines
Universal approximation depth and errors of narrow belief networks with discrete units
Approximation properties of DBNs with binary hidden units and real-valued visible units