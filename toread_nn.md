Learning internal representations by error propagation
Approximations by superpositions of sigmoidal functions
Approximation capabilities of multilayer feedforward networks
Approximation with Artificial Neural Networks
Universal approximation of an unknown mapping and its derivatives using multilayer feedforward networks
Degree of approximation results for feedforward networks approximating unknown mappings and their derivatives
Networks with trainable amplitude of activation functions
Polynomial Regression As an Alternative to Neural Nets
Neural clouds for monitoring of complex systems
Generalized Constraint Neural Network Regression Model Subject to Linear Priors
Learning from hints in neural networks
Hints and the VC Dimension
Efficient Pattern Recognition Using a New Transformation Distance
Financial Market Applications of Learning from Hints Neural Networks in the Capital Markets
Knowledge Incorporation into Neural Networks From Fuzzy Rules
Application of MLP networks to bond rating and house pricing
Calibrating artificial neural networks by global optimization   
https://deepmind.com/blog/population-based-training-neural-networks/
Practical Recommendations for Gradient-Based Training of Deep Architectures
Learning Inductive Biases with Simple Neural Networks
Rectified linear units improve restricted Boltzmann machines
Improving deep neural networks for LVCSR using rectified linear units and dropout
Deep learning via Hessian-free optimization
Extracting and composing robust features with denoising autoencoders
Efficient backprop
Saturating auto-encoders
Scalable Bayesian optimization using deep neural networks
Learning representations by back-propagating errors
Deep learning with limited numerical precision
Applied Optimal Control: Optimization, Estimation, and Control <- one of the original backpropagation
Beyond Regression: New Tools for Prediction and Analysis in the Behavioral Sciences <- one of the original backpropagation
Learning-logic: Casting the cortex of the human brain in silicon
Deep neuroevolution: Genetic algorithms are a competitive alternative for training deep neural networks for reinforcement learning
A memoryless BFGS neural network training algorithm
Regularization tools for training large feed-forward neural networks using automatic differentiation
Application of PID controller based on BP neural network using automatic differentiation method
Optimization of neural network feedback control systems using automatic differentiation
Caffe con troll: Shallow ideas to speed up deep learning
cuDNN: Efficient primitives for deep learning
Binaryconnect: Training deep neural networks with binary weights during propagations
Differentiable optimization as a layer in neural networks
Transformation invariance in pattern recognition, tangent distance and tangent propagation
Understanding the difficulty of training deep feedforward neural networks
Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift
Perceprrons
Neural Machine Translation by Jointly Learning to Align and Translate
A learned representation for artistic style
Empirical evaluation of rectified activations in convolutional network
Fast and accurate deep network learning by exponential linear units (elus)
Hypernetworks
Learning feed-forward one-shot learners
Dynamic filter networks
Why Should I Trust You Explaining the Predictions of Any Classifier
https://www.oreilly.com/learning/introduction-to-local-interpretable-model-agnostic-explanations-lime
https://www.kaggle.com/emanceau/interpreting-machine-learning-lime-explainer
https://github.com/marcotcr/lime
Learning in linear networks: a survey
Neural Network Design and the Complexity of Learning
The loading problem for pyramidal neural networks
Loading deep networks is hard
Loading deep networks is hard: The pyramidal case
Graphical models: foundations of neural computation
Sumâ€“product networks: A new deep architecture
Leveraging hierarchical parametric networks for skeletal joints based action segmentation and recognition
Stacked denoising autoencoders: Learning useful representations in a deep network with a local denoising criterion
Parallel networks that learn to pronounce English text
Scaling relationships in backpropagation learning
What size net gives valid generalization
On the complexity of polyhedral separability
Perceptrons An Introduction to Computational Geometry